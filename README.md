

# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS

# Aim: To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

### AI Tools Required: 

# Explanation: 
Define the Two Prompt Types:

Write a basic Prompt: Clear, detailed, and structured prompts that give specific instructions or context to guide the model.
Based on that pattern type refined the prompt and submit that with AI tool.
Get the ouput and write the report.

Prepare Multiple Test Scenarios:
Select various scenarios such as:
Generating a creative story.
Answering a factual question.
Summarizing an article or concept.
Providing advice or recommendations.
Or Any other test scenario
For each scenario, create both a naïve and a basic prompt. Ensure each pair of prompts targets the same task but with different levels of structure.
Run Experiments with ChatGPT:
Input the naïve prompt for each scenario and record the generated response.
Then input the corresponding basic prompt and capture that response.
Repeat this process for all selected scenarios to gather a full set of results.
Evaluate Responses : 
	Compare how ChatGPT performs when given naïve versus basic prompts and analyze the output based on Quality,Accuracy and Depth. Also analyse does ChatGPT consistently provide better results with basic prompts? Are there scenarios where naïve prompts work equally well?
Deliverables:
A table comparing ChatGPT's responses to naïve and basic prompts across all scenarios.
Analysis of how prompt clarity impacts the quality, accuracy, and depth of ChatGPT’s outputs.
Summary of findings with insights on how to structure prompts for optimal results when using ChatGPT.


# OUTPUT

## AI Prompt Evaluation Report

### Objective:
To evaluate how different AI models respond to broad/unstructured prompts versus refined/structured prompts across multiple scenarios, analyzing the quality, accuracy, depth, and creativity of their responses.

### 1. Methodology

Prompt Types:

Broad / Unstructured: Open-ended prompts with minimal guidance.

Refined / Structured: Clear, specific instructions designed to reduce ambiguity.

Scenarios Tested:

Coding / Algorithms

Data Analysis

Creative Writing

Knowledge Retrieval

Problem Solving

Evaluation Metrics:

Accuracy: Correctness of response

Completeness: Whether all aspects of the task were addressed

Clarity: Ease of understanding and readability

Depth: Insightfulness and level of detail

Creativity: Originality (for creative tasks)

Scoring:
1 = Poor, 2 = Fair, 3 = Good, 4 = Very Good, 5 = Excellent

### 2. Results Summary
Scenario	Prompt Type	AI Model	Accuracy	Completeness	Clarity	Depth	Creativity	Observations
Coding / Algorithm	Broad	GPT-5	3	3	3	2	2	Response was generic and lacked step-by-step explanation.
Coding / Algorithm	Refined	GPT-5	5	5	5	5	4	Provided stepwise solution with clear examples; very accurate.
Data Analysis	Broad	GPT-5	3	4	3	3	2	Covered general analysis but missed key metrics.
Data Analysis	Refined	GPT-5	5	5	5	5	3	Fully addressed the problem with detailed metrics and interpretation.
Creative Writing	Broad	GPT-5	4	3	4	4	5	Interesting ideas but lacked coherent structure.
Creative Writing	Refined	GPT-5	5	5	5	5	5	Clear, imaginative story with logical flow and strong character development.
Knowledge Retrieval	Broad	GPT-5	3	3	4	3	2	Correct info but incomplete, missing references/examples.
Knowledge Retrieval	Refined	GPT-5	5	5	5	5	3	Accurate and complete, well-structured response.
Problem Solving	Broad	GPT-5	2	3	3	2	2	Missed key steps; solution incomplete.
Problem Solving	Refined	GPT-5	5	5	5	5	4	Stepwise solution provided with detailed reasoning and correct answer.
3. Analysis and Insights

### Broad Prompts:

Responses tend to be generic, sometimes incomplete or lacking detail.

Creativity may be higher for open-ended tasks but often at the cost of clarity or depth.

Refined Prompts:

Responses are generally more accurate, complete, and structured.

Provide step-by-step reasoning for problem-solving and coding tasks.

Maintain high clarity and depth, even for complex scenarios.

Overall Observation:
Refined, structured prompts consistently yield higher-quality outputs, especially for tasks that require precision, stepwise reasoning, or analytical depth. Broad prompts may be useful for brainstorming or creative exploration but are less reliable for precise answers.

### 4. Recommendations

Use refined/structured prompts when accuracy, completeness, and clarity are critical (e.g., coding, analytics, knowledge retrieval).

Use broad prompts for exploratory or creative tasks where multiple perspectives or novel ideas are desired.

Combine approaches: start with broad prompts for idea generation, then refine prompts for detailed solutions.

Maintain a consistent evaluation framework (accuracy, completeness, clarity, depth, creativity) to benchmark AI responses systematically.

# RESULT: 

The prompt for the above said problem executed successfully
